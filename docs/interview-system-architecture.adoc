= System Architecture Interview
:imagesdir: images/interview

== Scenario
We're building a migration tool that reads from a relational database and writes to Redis streams.

The system should be designed to write to Redis streams but be extensible to other Redis data structures (hashes, strings, JSON, etc.).

Additionally, the system must be:

* Highly available and scalable for all components (readers, processors, writers).
* Handle non-durable events that come in bursts from the source (i.e. handle traffic spikes).
* Resilient to source and target failures
* Multithreading and job management (consider in-memory queues vs transient Redis Streams).

Start with the naive case of a SQL query to read from database tables but keep in mind the real use case is Change Data Capture (reading from a transaction log that could be non-durable and bursty).

image::architecture.svg[]

== Interview Structure (45 minutes)

=== 1. High-Level Architecture Design (10 mins)
- _Question_: How would you design a migration tool that reads from an event source and writes to Redis streams, ensuring it can be extended to other Redis data structures and handles scalability and availability at the source, worker processes, and target Redis database?
- _Focus_: Evaluate understanding of modular design, abstraction for Redis data structures, and general approach to handling availability and scalability across the system.
- _Expected Answers_:
  * Separation of concerns between the reader, worker processes, and writer.
  * Abstraction for Redis data structure flexibility.
  * Use of queues or buffers to handle traffic spikes and decouple components.

=== 2. Handling Traffic Spikes at the Source (7 mins)
- _Question_: How would you handle non-durable events coming in bursts at the source? How do you design the reader to handle traffic spikes while ensuring availability?
- _Focus_: Assess strategies for buffering and scaling the reader during spikes.
- _Expected Answers_:
  * In-memory queue or Redis Streams as buffers.
  * Elastic scaling of readers to handle burst traffic.
  * Backpressure mechanisms to control event consumption.

=== 3. Worker Processes: Multithreading and Job Management (8 mins)
- _Question_: How would you design the worker processes to support multithreading, job management, and scalability across multiple processes?
- _Focus_: Test understanding of concurrency, job distribution, and scaling workers horizontally.
- _Expected Answers_:
  * Multithreading with job queues for parallel task processing.
  * Load balancing across worker processes using in-memory queues or Redis Streams.
  * Handling failures and job reassignment in a multi-worker environment.

=== 4. Handling Redis Downtime and Resilience (7 mins)
- _Question_: What would you do if the target Redis database is down? How would you ensure the system remains resilient and available?
- _Focus_: Explore how the candidate handles failure scenarios and ensures data availability.
- _Expected Answers_:
  * Retry strategy with backoff for failed writes.
  * Temporary storage of events in queues until Redis is back online.
  * Idempotent writes and deduplication to prevent data loss.

=== 5. Performance vs Scalability (7 mins)
- _Question_: How would you ensure that the system handles increasing data volumes without sacrificing performance, especially during traffic spikes?
- _Focus_: Test the candidate's approach to optimizing for both performance and scalability.
- _Expected Answers_:
  * Batching, pipelining to optimize throughput.
  * Dynamic scaling of workers and efficient resource utilization.
  * Monitoring and addressing bottlenecks (network, I/O, Redis CPU).

=== 6. Conclusion and Summary (6 mins)
- Summarize the candidate’s approach, ask for final thoughts on trade-offs between latency, availability, and throughput, and how they'd monitor and evolve the system.
- Evaluate their approach to designing scalable, resilient systems with a focus on real-world scenarios.

== General Topics

Various system design topics, including pros and cons.
*Everything is a trade-off*.

=== Performance vs Scalability

Performance problem if your system is slow for a single user.
Scalability problem if your system is fast for a single user but slow under load.

=== Latency vs Throughput

Latency is the time to perform some action
Throughtput is number of actions performed per unit of time
Usually need to maximize throughput with acceptable latency.

=== Availability vs Consistency

CAP Theorem
CP: Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.
AP: Responses return the most recent version of the data available on a node, which might not be the latest. Writes might take some time to propagate when the partition is resolved.

==== Consistency patterns
Weak: After a write, reads may or may not see it. A best effort approach is taken.
Eventual:  After a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.
Strong: After a write, reads will see it. Data is replicated synchronously.

==== Availability patterns
* Fail-over
* Replication
* Active/passive
* Active/active
* 9s
** three 9s: 8h/year, 1m26s a day
** four 9s: 52min/year, 9s a day

=== Databases

==== Database Types
* SQL vs noSQL (kv, document, timeseries, ...)
* ACID vs eventual consistency

==== Data Structures
* Normalization/denormalization
* Joins

==== Replication
* Active/passive: 
* Active/active
** either loosely consistent (violating ACID)
** or increased write latency due to synchronization
** Conflict resolution (CRDB)
* Geo-replication

==== Scalability and performance
* Sharding
* Caching
* Indexing
** CPU/memory trade-off
** Index types: hash vs tree

==== Operating systems
* File system: fsync
* Disk vs Memory
** DDR4 latency: ~20ns
** SSD latency: ~25μs
* CPU

==== Networking
* TCP/IP stack
* HTTP
* RESP
* Batching
* Latency vs throughput

==== Concurrency
* Threads
* Processes
* Threading in the language you know
* Locks
* Mutex
* Etc.


==== Observability
* Logging
* Metrics
* Tracing

==== Web
* Load balancers/proxies

==== Distributed Systems
* CAP theorem basics and designing scalable systems
* Distribution vs replication
* Queues
* Pub/sub

